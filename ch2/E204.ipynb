{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9a1eb4-1f34-46b5-8b6a-05626358db0b",
   "metadata": {},
   "source": [
    "# Splitting the data\n",
    "\n",
    "It's important to split the data for your research into different categories.\n",
    "\n",
    "1. Training.\n",
    "\n",
    "This is the data that the NN is trained with. With supervised learning, it consists of features and the target value(s).\n",
    "\n",
    "2. Validation\n",
    "\n",
    "This set is used to measure performance of the model in order to make adjustments. \n",
    "\n",
    "3. Testing\n",
    "\n",
    "This set doesn't have an effect on the model, which is why it is used to evaluate the model on previously unseen and untrained data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2321c4-5e67-41f6-9fa8-0616a694576f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19735, 28)\n",
      "<bound method NDFrame.head of        Appliances  lights         T1       RH_1         T2       RH_2  \\\n",
      "0              60      30  19.890000  47.596667  19.200000  44.790000   \n",
      "1              60      30  19.890000  46.693333  19.200000  44.722500   \n",
      "2              50      30  19.890000  46.300000  19.200000  44.626667   \n",
      "3              50      40  19.890000  46.066667  19.200000  44.590000   \n",
      "4              60      40  19.890000  46.333333  19.200000  44.530000   \n",
      "...           ...     ...        ...        ...        ...        ...   \n",
      "19730         100       0  25.566667  46.560000  25.890000  42.025714   \n",
      "19731          90       0  25.500000  46.500000  25.754000  42.080000   \n",
      "19732         270      10  25.500000  46.596667  25.628571  42.768571   \n",
      "19733         420      10  25.500000  46.990000  25.414000  43.036000   \n",
      "19734         430      10  25.500000  46.600000  25.264286  42.971429   \n",
      "\n",
      "              T3       RH_3         T4       RH_4  ...         T9     RH_9  \\\n",
      "0      19.790000  44.730000  19.000000  45.566667  ...  17.033333  45.5300   \n",
      "1      19.790000  44.790000  19.000000  45.992500  ...  17.066667  45.5600   \n",
      "2      19.790000  44.933333  18.926667  45.890000  ...  17.000000  45.5000   \n",
      "3      19.790000  45.000000  18.890000  45.723333  ...  17.000000  45.4000   \n",
      "4      19.790000  45.000000  18.890000  45.530000  ...  17.000000  45.4000   \n",
      "...          ...        ...        ...        ...  ...        ...      ...   \n",
      "19730  27.200000  41.163333  24.700000  45.590000  ...  23.200000  46.7900   \n",
      "19731  27.133333  41.223333  24.700000  45.590000  ...  23.200000  46.7900   \n",
      "19732  27.050000  41.690000  24.700000  45.730000  ...  23.200000  46.7900   \n",
      "19733  26.890000  41.290000  24.700000  45.790000  ...  23.200000  46.8175   \n",
      "19734  26.823333  41.156667  24.700000  45.963333  ...  23.200000  46.8450   \n",
      "\n",
      "           T_out  Press_mm_hg     RH_out  Windspeed  Visibility  Tdewpoint  \\\n",
      "0       6.600000        733.5  92.000000   7.000000   63.000000   5.300000   \n",
      "1       6.483333        733.6  92.000000   6.666667   59.166667   5.200000   \n",
      "2       6.366667        733.7  92.000000   6.333333   55.333333   5.100000   \n",
      "3       6.250000        733.8  92.000000   6.000000   51.500000   5.000000   \n",
      "4       6.133333        733.9  92.000000   5.666667   47.666667   4.900000   \n",
      "...          ...          ...        ...        ...         ...        ...   \n",
      "19730  22.733333        755.2  55.666667   3.333333   23.666667  13.333333   \n",
      "19731  22.600000        755.2  56.000000   3.500000   24.500000  13.300000   \n",
      "19732  22.466667        755.2  56.333333   3.666667   25.333333  13.266667   \n",
      "19733  22.333333        755.2  56.666667   3.833333   26.166667  13.233333   \n",
      "19734  22.200000        755.2  57.000000   4.000000   27.000000  13.200000   \n",
      "\n",
      "             rv1        rv2  \n",
      "0      13.275433  13.275433  \n",
      "1      18.606195  18.606195  \n",
      "2      28.642668  28.642668  \n",
      "3      45.410389  45.410389  \n",
      "4      10.084097  10.084097  \n",
      "...          ...        ...  \n",
      "19730  43.096812  43.096812  \n",
      "19731  49.282940  49.282940  \n",
      "19732  29.199117  29.199117  \n",
      "19733   6.322784   6.322784  \n",
      "19734  34.118851  34.118851  \n",
      "\n",
      "[19735 rows x 28 columns]>\n"
     ]
    }
   ],
   "source": [
    "%run E203.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8fa5d4d-4b73-4a35-8454-70d7302cad13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19735, 27)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # output should be (19735,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b735264-8b93-4705-8e21-4610d2e1b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the upper and lower bound for training and validation sets. this will be used to split the dataset into a 60:20:20 arrangement\n",
    "train_end = int(len(x) * 0.6)\n",
    "dev_end = int(len(x) * 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ad145-2b6b-4a5c-84ea-e3b651b59bd6",
   "metadata": {},
   "source": [
    "Now we must shuffle the dataset to help remove bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a631d1-e3e7-4beb-9008-06a677024ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shuffle = x.sample(frac=1, random_state=0)\n",
    "y_shuffle = y.sample(frac=1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70225d-361b-4b67-9b3a-bb64a9a75649",
   "metadata": {},
   "source": [
    "Now use indexing to split the shuffled dataset into the three sets for both features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ecc708-d5c6-41da-a883-806deddbffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_shuffle.iloc[:train_end,:]\n",
    "y_train = y_shuffle.iloc[:train_end]\n",
    "x_dev   = x_shuffle.iloc[train_end:dev_end,:]\n",
    "y_dev   = y_shuffle.iloc[train_end:dev_end]\n",
    "x_test  = x_shuffle.iloc[dev_end:,:]\n",
    "y_test  = y_shuffle.iloc[dev_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c7a9955-36d5-44e9-b3a0-8a6e7fe3933b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11841, 27) (11841,)\n",
      "(3947, 27) (3947,)\n",
      "(3947, 27) (3947,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_dev.shape, y_dev.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a05f99-f3af-4caa-92ad-a5cc3f917d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # put here just for continuity of material and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03dd955-b270-43a5-8ec8-150901ee1c73",
   "metadata": {},
   "source": [
    "Now we must split the shuffled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "212551f1-0b10-4933-b830-0e5b2d77c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform an initial split where the first two params are the dataset to be split, test_size is the % of instances to be contained, \n",
    "# and random_state is set to 0 for reproducability\n",
    "x_new, x_test_2, y_new, y_test_2 = train_test_split(x_shuffle, y_shuffle, test_size=0.2, random_state=0)\n",
    "dev_per = x_test_2.shape[0]/x_new.shape[0]\n",
    "x_train_2, x_dev_2, y_train_2, y_dev_2 = train_test_split(x_new, y_new, test_size=dev_per, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8035d782-e4e6-4019-ac56-7986bdcb2019",
   "metadata": {},
   "source": [
    "Print the shape of all three sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb706086-6427-4240-a938-e471301305a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11841, 27) (11841,)\n",
      "(3947, 27) (3947,)\n",
      "(3947, 27) (3947,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_2.shape, y_train_2.shape)\n",
    "print(x_dev_2.shape, y_dev_2.shape)\n",
    "print(x_test_2.shape, y_test_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb1f981-eb97-4162-b192-5db8b6a2b32b",
   "metadata": {},
   "source": [
    "As you can see, the resulting sets have the same shape, using the indexing approach or `sklearn.train_test_split` is a matter of preference, but i personally think using indexes makes more sense and is simpler code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
